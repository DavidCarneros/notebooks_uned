{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tema 5 estadistica.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavidCarneros/notebooks_uned/blob/main/Tema_5_estadistica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cx7nJz1r3E5h"
      },
      "source": [
        "# **Tema 5: Regresión lineal**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIDNe6qnoUM6"
      },
      "source": [
        "En este tema se verán algunos conceptos básicos relativos a la regresión lineal, que está indicada en la modelización de una variable respuesta $Y$ **continua** a través de varias variables explicativas $X_1, X_2, ... , X_p$. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9kXak_U3Mmj"
      },
      "source": [
        "## Regresión lineal simple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ruo-73X47NEa"
      },
      "source": [
        "La *regresión lineal simple* hace honor a su nombre: es un enfoque muy sencillo para predecir una respuesta cuantitativa $Y$ sobre la base de una única variable predictora $X$. Asume que hay aproximadamente una relación lineal entre $X$ e $Y$. Matemáticamente, podemos escribir esta relación lineal como:\n",
        "\n",
        "$$ Y \\approx \\beta_0 + \\beta_1 X $$\n",
        "\n",
        "Por ejemplo, $X$ puede representar la publicidad de TV e $Y$ puede representar las ventas. Entonces podemos hacer una regresión de las ventas a la TV ajustando el modelo:\n",
        "\n",
        "$$ sales \\approx \\beta_0 + \\beta_1 TV $$\n",
        "\n",
        "Donde $\\beta_0$ y $\\beta_1$ son dos constantes desconocidas que representan\n",
        "los términos de intersección y pendiente en el modelo lineal. En su conjunto, $\\beta_0$ y $\\beta_1$ y se conocen como **parámetros** o **coeficientes** del modelo.  Una vez que hemos usado nuestro conjunto de entrenamiento para estimar los valores $ \\hat{\\beta}_0$ y $\\hat{\\beta}_1 $ del modelo, podemos predecir las ventas futuras sobre la base de un valor particular de la publicidad televisiva calculando \n",
        "\n",
        "$$ \\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 x$$\n",
        "\n",
        "Donde $\\hat{y}$ indica una predicción de Y en base a X = x."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egnVCaiH3eDO"
      },
      "source": [
        "### Estimación de los coeficientes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5g1FPxC--yqi"
      },
      "source": [
        "En la práctica, $\\beta_0$ y $\\beta_1$ son desconocidos, por lo que debemos usar datos para estimar dichos coeficientes. Representamos $n$ pares de observación, cada uno de los cuales consta de una medida de $X$ y una medida de $Y$. $\\{ (x_1,y_1), (x_2, y_2), ..., (x_n,y_n)\\}$. Nuestro objetivo es obtener estimaciones de coeficientes $\\hat{\\beta}_0$ y $\\hat{\\beta}_1$ de manera que el modelo lineal se ajuste bien a los datos disponibles. \n",
        "\n",
        "Sea $\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_1$ la predicción para $Y$ basada en el i-ésimo valor de $X$. Entonces $e_i = y_i − \\hat{y}_i$ representa el iésimo residual: esta es la diferencia entre el iésimo valor de respuesta observado y el iésimo valor de respuesta que predice nuestro modelo lineal . Definimos la **suma de los cuadrados de los residuos** (*residual sum of squares*, RSS) como:\n",
        "\n",
        "$$ RSS = e_1^2 + e_2^2 + ... + e_n^2$$\n",
        "\n",
        "o, de manera equivalentemente:\n",
        "\n",
        "$$ RSS  = (y_1 - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_1)^2 + (y_2 - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_2)^2 + ... + (y_n - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_n)^2 $$\n",
        "\n",
        "El enfoque de **mínimos cuadrados** elige $\\hat{\\beta}_0$ y $\\hat{\\beta}_1$ para minimizar el RSS. Usando algo de cálculo, se puede demostrar que los minimizadores son:\n",
        "\n",
        "$$ \\hat{\\beta}_1 = \\frac{ \\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2} $$\n",
        "\n",
        "$$ \\hat{\\beta}_0 = \\hat{y} - \\hat{\\beta}_1 \\bar{x} $$\n",
        "\n",
        "Donde $\\bar{y} = \\frac{1}{n} \\sum_{i=1}^n y_i$ y $\\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i$ son las medias muestrales. En otras palabras, define las estimaciones del coeficiente de mínimos cuadrados para la regresión lineal simple.\n",
        "\n",
        "<center>\n",
        "<p>\n",
        "<img src=\"https://i.gyazo.com/13b3d0c087e09c4c016ace594efd02c2.png \" width=\"57%\"/>\n",
        "<figcaption>Fig.1 - Regresión lineal simple para el dataset Advertising </figcaption>\n",
        "</p>\n",
        "</center>\n",
        "\n",
        "La Figura 1 muestra el ajuste de regresión lineal simple a los datos de Advertising. En la Figura 2, hemos calculado RSS para una serie de valores de $\\beta_0$ y $\\beta_1$, utilizando los datos publicitarios con ventas como respuesta y TV como predictor. En cada gráfico, el punto rojo representa el par de estimaciones de mínimos cuadrados $(\\hat{\\beta}_0, \\hat{\\beta}_1)$. Estos valores minimizan claramente el RSS\n",
        "\n",
        "\n",
        "<center>\n",
        "<p>\n",
        "<img src=\"https://i.gyazo.com/8ac35f0fd7fba5cb05adb99fa6ec6561.png\" width=\"57%\"/>\n",
        "<figcaption>Fig.2 - RSS sobre el dataset de Advertising </figcaption>\n",
        "</p>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJmt0cmg3hVr"
      },
      "source": [
        "### Evaluar la precisión de las estimaciones de coeficientes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iA8WHsLSTGP6"
      },
      "source": [
        "Suponemos que la verdadera relación entre $X$ e $Y$ toma la forma $Y = f (X) + \\epsilon$ para alguna función $f$ desconocida, donde $\\epsilon$ es un término de error aleatorio de media cero.  Si $f$ se aproxima mediante una función lineal, entonces podemos escribir esta relación como: \n",
        "\n",
        "$$ Y = \\beta_0 + \\beta_1X + \\epsilon$$\n",
        "\n",
        "Donde $\\beta_0$ es el término de intersección, es decir, el valor esperado de $Y$ cuando $X = 0$, y $\\beta_1$ es la pendiente - el aumento medio de $Y$ asociado al aumento de una unidad en $X$. El término de error es una expresión que representa cómo nos equivocamos con este modelo simple, y es que la verdadera relación probablemente no es lineal, es decir, puede haber otras variables que causan variación en Y.\n",
        "\n",
        "El modelo dado por la ecuación superior define la **línea de regresión de la población**, que es la mejor aproximación lineal a la verdadera relación entre $X$ e $Y$. Las estimaciones del coeficiente de regresión de los mínimos cuadrados caracterizan la **línea de mínimos cuadrados**. El panel de la izquierda de la Figura 3 muestra estas dos líneas en un ejemplo simulado simple. Creamos 100 X aleatorios y generamos 100 Y correspondientes del modelo.\n",
        "\n",
        "$$ Y = 2 + 3X + \\epsilon$$\n",
        "\n",
        "donde $\\epsilon$ se generó a partir de una distribución normal con media cero. La línea roja en el panel de la izquierda de la Figura 3 muestra la relación verdadera, $f (X) = 2 + 3X$, mientras que la línea azul es la estimación de mínimos cuadrados basada en los datos observados. La verdadera relación generalmente no se conoce para datos reales, pero la línea de mínimos cuadrados siempre se puede calcular utilizando las estimaciones de coeficientes en aplicaciones reales, tenemos acceso a un conjunto de observaciones a partir de las cuales podemos calcular la línea de mínimos cuadrados. Observe que los diferentes conjuntos de datos generados a partir del mismo modelo verdadero dan como resultado líneas de mínimos cuadrados ligeramente diferentes, pero la línea de regresión de la población no observada no cambia\n",
        "\n",
        "<center>\n",
        "<p>\n",
        "<img src=\"https://i.gyazo.com/51631f17864e09eea494963e71dd4925.png\" width=\"57%\"/>\n",
        "<figcaption>Fig.3 - Dataset simulado </figcaption>\n",
        "</p>\n",
        "</center>\n",
        "\n",
        "Por ejemplo, supongamos que estamos interesados en conocer la media poblacional $ \\mu $ de alguna variable aleatoria $Y$. Desafortunadamente, $\\mu$ es desconocido, pero tenemos acceso a $n$ observaciones de $Y$, que podemos escribir como $y_1, ..., y_n$, y que podemos usar para estimar $\\mu$. Una estimación razonable es $\\hat{\\mu} = \\bar{y}$, donde $ \\hat{y} = \\frac{1}{n}\\sum_{i_1}^n y_i$ es la media de la muestra. La media de la muestra y la media de la población son diferentes, pero en general la media de la muestra proporcionará una buena estimación de la media de la población. De la misma manera, los coeficientes desconocidos $\\beta_0$ y $\\beta_1$ en la regresión lineal definen la línea de regresión poblacional.\n",
        "\n",
        "La analogía entre la regresión lineal y la estimación de la media de una variable aleatoria es adecuada basada en el concepto de sesgo Si usamos la media muestral $\\hat{\\mu}$ para estimar $\\mu$, esta estimación es insesgada, en el sentido de que, en promedio, esperamos $\\hat{\\mu}$ para igualar $\\mu$. Significa que sobre la base de un conjunto particular de observaciones $y_1, ..., y_n$, $\\hat{\\mu}$ podría sobreestimar $\\mu$, y sobre la base de otro conjunto de observaciones, $\\hat{\\mu}$ podría subestimar $\\mu$. Pero si pudiéramos promediar una gran cantidad de estimaciones de $\\mu$ obtenidas a partir de una gran cantidad de conjuntos de observaciones, entonces esta media sería exactamente igual a $\\mu$. Por lo tanto, un estimador insesgado no sobreestima ni subestima sistemáticamente el parámetro verdadero.\n",
        "\n",
        "Continuamos con la analogía con la estimación de la media poblacional $\\mu$ de una variable aleatoria $Y$. Una pregunta natural es la siguiente: ¿cuán precisa es la media muestral $\\hat{\\mu}$ como una estimación de $\\mu$? Hemos establecido que el promedio de $\\hat{\\mu}$ sobre muchos conjuntos de datos será muy cercano a $\\mu$, pero que una sola estimación $\\hat{\\mu}$ puede ser una subestimación o sobreestimación sustancial de $\\mu$. ¿Qué tan lejos estará esa estimación única de $\\hat{\\mu}$? En general, respondemos a esta pregunta calculando el error estándar de $\\hat{\\mu}$, escrito como $SE (\\hat{\\mu})$. Tenemos la conocida fórmula: \n",
        "\n",
        "$$ Var(\\hat{\\mu}) = SE(\\hat{\\mu})^2 = \\frac{\\sigma^2}{n} $$\n",
        "\n",
        "donde $\\sigma$ es la desviación estándar de cada una de las realizaciones $y_i$ de $Y$. El error estándar nos dice la cantidad promedio en la que esta estimación $\\hat{\\mu}$ difiere del valor real de $\\mu$. Para calcular los errores estándar asociados con $\\hat{\\beta}_0$ y $\\hat{\\beta}_1$, usamos las siguientes fórmulas:\n",
        "\n",
        "$$ SE(\\hat{\\beta}_0)^2 = \\sigma^2 \\left[ \\frac{1}{n} + \\frac{\\bar{x}^2}{\\sum_{i=1}^n (x_i - \\bar{x})^2} \\right]$$\n",
        "$$ SE(\\hat{\\beta}_1)^2 =  \\frac{1}{n} + \\frac{\\sigma^2}{\\sum_{i=1}^n (x_i - \\bar{x})^2} $$\n",
        "\n",
        "donde $\\sigma^2 = Var(\\epsilon)$. Para que estas fórmulas sean estrictamente válidas, debemos asumir que los errores $\\epsilon_i$ para cada observación no están correlacionados con la varianza común $\\sigma^2$. También vemos que $SE(\\hat{\\beta_0})$ sería lo mismo que $SE(\\hat{\\mu})$ si $\\bar{x}$ fuera cero (en cuyo caso $\\hat{\\beta_0}$ sería igual a $\\bar{y}$). En general, $\\sigma^2$ no se conoce, pero se puede estimar a partir de los datos. La estimación de $\\sigma$ se conoce como error estándar residual y viene dada por la fórmula $RSE = \\sqrt{\\frac{RSS}{n-2}}$. Estrictamente hablando, cuando se estima $\\sigma^2$ a partir de los datos, debemos escribir $\\hat{SE}(\\hat{\\beta}_1)$ para indicar que se ha realizado una estimación, pero para simplificar la notación, eliminaremos este “sombrero” adicional.\n",
        "\n",
        "Los errores estándar se pueden utilizar para calcular los intervalos de confianza. Un intervalo de confianza del 95% se define como un rango de valores tal que, con una probabilidad del 95%, el rango contendrá el verdadero valor desconocido del parámetro. Para la regresión lineal, el intervalo de confianza del 95% para $\\beta_1$ toma aproximadamente la forma:\n",
        "\n",
        "$$ \\hat{\\beta}_1 \\mp 2·SE(\\hat{\\beta}_1) $$\n",
        "\n",
        "contendrá el valor real de $\\beta_1$. De manera similar, un intervalo de confianza para $\\beta_0$ aproximadamente toma la forma:\n",
        "\n",
        "$$ \\hat{\\beta}_0 \\mp 2·SE(\\hat{\\beta}_0) $$\n",
        "\n",
        "En el caso de los datos publicitarios, el intervalo de confianza del 95% para $\\beta_0$ es [6.130,7.935] y el intervalo de confianza del 95% para $\\beta_1$ es [0.042,0.053]. Por lo tanto, podemos concluir que en ausencia de publicidad, las ventas , en promedio, se ubican entre 6,130 y 7,940 unidades. Además, por cada aumento de $ 1,000 en publicidad televisiva, habrá un aumento promedio en las ventas de entre 42 y 53 unidades.\n",
        "\n",
        "Los errores estándar también se pueden utilizar para realizar pruebas de hipótesis sobre los coeficientes de la prueba de hipótesis. La prueba de hipótesis más común implica probar la hipótesis nula de:\n",
        "\n",
        "<center>\n",
        "$H_0:$ No hay relacion entre $X$ e $Y$\n",
        "\n",
        "$H_a$: Hay alguna relacion entre $X$ e $Y$\n",
        "</center>\n",
        "\n",
        "Matematicamente: $H_0 : \\beta_1 = 0$; $H_a = \\beta_1 \\ne 0$ ya que si $\\beta_1 = 0$ entonces el modelo se reduce a $Y = \\beta_0 + \\epsilon$, y $X$ no está asociado con $Y$. Para probar la hipótesis nula, necesitamos determinar si $\\hat{\\beta}_1$, nuestra estimación para $\\beta_1$, está lo suficientemente lejos de cero que podemos estar seguros de que $\\beta_1$ no es cero. Esto, por supuesto, depende de la precisión de $\\hat{\\beta}_1$, es decir, depende de $SE(\\hat{\\beta}_1)$. Si $SE(\\hat{\\beta}_1)$ es pequeño, entonces incluso valores relativamente pequeños de $\\hat{\\beta}_1$ pueden proporcionar una fuerte evidencia de que $\\beta_1 \\ne 0$ y, por lo tanto, existe una relación entre $X$ e $Y$. Por el contrario, si $SE(\\hat{\\beta}_1)$ es grande, entonces $\\hat{\\beta}_1$ debe ser grande en valor absoluto para que podamos rechazar la hipótesis nula. En la práctica, calculamos un estadístico t dado por:\n",
        "\n",
        "$$ t = \\frac{\\hat{\\beta}_1 - 0}{SE(\\hat{\\beta}_1)}$$\n",
        "\n",
        "que mide el número de desviaciones estándar en las que $\\hat{\\beta}_1$ está alejado de 0. Si realmente no hay relación entre $X$ e $Y$, entonces esperamos que tenga una distribución $t$ con $n − 2$ grados de libertad. La distribución $t$ tiene forma de campana y para valores de $n$ superiores a aproximadamente 30 es bastante similar a la distribución normal. En consecuencia, es una cuestión sencilla calcular la probabilidad de observar cualquier número igual a $|t|$ o mayor en valor absoluto, asumiendo $\\beta_1 = 0$. A esta probabilidad la llamamos *p-valor*. \n",
        "\n",
        "En términos generales, interpretamos el *p-valor* de la siguiente manera: un *p-valor* pequeño indica que es poco probable que se observe una asociación tan sustancial entre el predictor y la respuesta debida al azar, en ausencia de una asociación real entre el predictor y el factor pronóstico. respuesta. Por lo tanto, si vemos un valor *p-valor*, podemos inferir que existe una asociación entre el predictor y la respuesta. Rechazamos la hipótesis nula, es decir, declaramos que existe una relación entre $X$ e $Y$. \n",
        "\n",
        "<center>\n",
        "<p>\n",
        "<img src=\"https://i.gyazo.com/20280d3d686b3099c55a7a1672af0a94.png\" width=\"57%\"/>\n",
        "<figcaption>Fig.4 - Coeficientes del dataset Advertising </figcaption>\n",
        "</p>\n",
        "</center>\n",
        "\n",
        "La Figura 4 proporciona detalles del modelo de mínimos cuadrados para la regresión del número de unidades vendidas en el presupuesto de publicidad televisiva para los datos de Advertising. Observe que los coeficientes para $\\hat{\\beta}_0$ y $\\hat{\\beta}_1$ son muy grandes en relación con sus errores estándar, por lo que los estadísticos $t$ son también grandes; las probabilidades de ver tales valores si $H_0$ es verdadera son virtualmente cero. Por tanto, podemos concluir que $\\beta_0 = 0 $ y $\\beta_1 = 0 $. Un *p-valor* pequeño para la intersección indica que podemos rechazar la hipótesis nula de que $\\beta_0 = 0$, y un *p-valor* pequeño para TV indica que podemos rechazar la hipótesis nula de que $\\beta_1 = 0$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ya-kcB5Q3oen"
      },
      "source": [
        "### Evaluación de la precisión del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kixiyrg_o6iY"
      },
      "source": [
        "Una vez que hemos rechazado la hipótesis nula a favor de la hipótesis alternativa, es natural querer cuantificar el grado en que el modelo se ajusta a los datos. La calidad de un ajuste de regresión lineal generalmente se evalúa utilizando dos cantidades relacionadas: el error estándar residual (RSE) y la estadística $R^2$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIK1c4PR3t7z"
      },
      "source": [
        "#### Error residual estandar\n",
        "\n",
        "Recuerde del modelo $ Y = \\beta_0 + \\beta_1X + \\epsilon$ que asociado con cada observación hay un término de error $\\epsilon$. No seríamos capaces de predecir perfectamente $Y$ a partir de $X$. El $RSE$ es una estimación de la desviación estándar de $\\epsilon$. En términos generales, es la cantidad promedio que la respuesta se desviará de la verdadera línea de regresión. Se calcula usando la fórmula:\n",
        "\n",
        "$$ RSE = \\sqrt{ \\frac{1}{n-2} RSS } = \\sqrt{\\frac{1}{n-2} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 }$$\n",
        "\n",
        "$$ RSS = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 $$ \n",
        "\n",
        "En el caso de los datos publicitarios (Advertising), vemos el resultado de la regresión lineal en la Figura 5. En otras palabras, las ventas reales en cada mercado se desvían de la línea de regresión verdadera en aproximadamente 3260 unidades, en promedio. Otra forma de pensar en esto es que incluso si el modelo fuera correcto y los verdaderos valores de los coeficientes desconocidos $\\beta_0$ y $\\beta_1$ se conocieran con exactitud, cualquier predicción de ventas basada en la publicidad televisiva estaría desviada en unas 3260 unidades de media.\n",
        "\n",
        "<center>\n",
        "<p>\n",
        "<img src=\"https://i.gyazo.com/00208ed63f90b566f6c27e3f0ea210fb.png\" width=\"40%\"/>\n",
        "<figcaption>Fig.5 - Mas informacion sobre minimos cuadrados del Dataset Advertising </figcaption>\n",
        "</p>\n",
        "</center>\n",
        "\n",
        "El $RSE$ se considera una medida de la falta de ajuste del modelo a los datos. Si las predicciones obtenidas con el modelo están muy cerca de los valores de resultado reales, es decir, si $\\hat{y}_i \\approx y_i$ para $i = 1, ..., n$,  entonces $RSE$ será pequeña y podemos concluir que el modelo se ajusta a los datos. muy bien. Por otro lado, si $\\hat{y}_i$ está muy lejos de $y_i$ para una o más observaciones, entonces el $RSE$ puede ser bastante grande, lo que indica que el modelo no se ajusta bien a los datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5YZ5e6a3w0I"
      },
      "source": [
        "#### Estadistico $R^2$ \n",
        "\n",
        "El $RSE$ proporciona una medida absoluta de la falta de ajuste del modelo a los datos. Pero como se mide en unidades de $Y$, no siempre está claro qué constituye un buen $RSE$. La estadística $R^2$ proporciona una medida alternativa de ajuste. Toma la forma de una proporción —la proporción de varianza explicada— y, por lo tanto, siempre toma un valor entre 0 y 1, y es independiente de la escala de $Y$.\n",
        "\n",
        "$$ R^2 = \\frac{TSS - RSS}{TSS} = 1 - \\frac{RSS}{TSS} $$\n",
        "\n",
        "$$ TSS = \\sum (y_i - \\hat{y})^2 $$\n",
        "\n",
        "$TSS$ mide la varianza total en la respuesta $Y$, y se puede considerar como la cantidad de variabilidad inherente a la respuesta antes de que se realice la regresión. Por el contrario, $RSS$ mide la cantidad de variabilidad que queda sin explicar después de realizar la regresión. Por lo tanto, $TSS-RSS$ mide la cantidad de variabilidad en la respuesta que se explica (o elimina) al realizar la regresión, y $R^2$ mide la proporción de variabilidad en $Y$ que se puede explicar usando $X$. Un estadístico $R^2$ cercano a 1 indica que una gran proporción de la variabilidad en la respuesta se ha explicado por la regresión. Un número cercano a 0 indica que la regresión no explicó gran parte de la variabilidad en la respuesta; esto puede ocurrir porque el modelo lineal es incorrecto, o el error inherente $\\sigma^2$ es alto, o ambos. En la Figura 5, el $R^2$ fue 0,61, por lo que poco menos de dos tercios de la variabilidad en las ventas se explica por una regresión lineal en la televisión.\n",
        "\n",
        "La estadística $R^2$ tiene una ventaja interpretativa sobre la $RSE$, ya que a diferencia de la $RSE$, siempre se encuentra entre 0 y 1. Sin embargo, aún puede ser un desafío determinar cuál es un buen valor de $R^2$ y, en general, esto dependerá de la aplicación. \n",
        "\n",
        "El estadístico $R^2$ es una medida de la relación lineal entre $X$ e $Y$. Recuerde que la correlación, definida como:\n",
        "\n",
        "$$ Cor(X,Y) = \\frac{\\sum_{i=1}^n (x_i - \\bar{x}) (y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^n (x_i - \\bar{x})^2} \\sqrt{\\sum_{i=1}^n (y_i - \\bar{y})^2} } $$\n",
        "\n",
        "es también una medida de la relación lineal entre $X$ e $Y$. Esto sugiere que podríamos usar $ r = Cor(X, Y)$ en lugar de $R^2$ para evaluar el ajuste del modelo lineal. De hecho, se puede demostrar que en la configuración de regresión lineal simple, $R^2 = r^2$. En otras palabras, la correlación al cuadrado y el estadístico $R^2$ son idénticos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZvybgtJ3RLQ"
      },
      "source": [
        "## Regresión lineal multiple\n",
        "\n",
        "La regresión lineal simple es un enfoque adecuado para predecir una respuesta en base a una única variable predictiva. Sin embargo, generalmente tenemos más\n",
        "de una variable predictora.  Por ejemplo, en el conjunto de datos de publicidad, hemos examinado la relación entre las ventas y la publicidad televisiva. Supongamos que también tenemos datos para la cantidad de dinero gastado en publicidad en la radio y en los periódicos,\n",
        "y queremos saber si alguno de estos dos medios también está asociado\n",
        "con las ventas.\n",
        "\n",
        "En general, si tenemos $p$ predictores distintos, el modelo de regresión múltiple establece que:\n",
        "\n",
        "$$Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_p X_p + \\epsilon_i $$\n",
        "\n",
        "donde $X_j$ representa el j-ésimo predictor y $\\beta_j$ cuantifica la relación entre dicha variable y la respuesta. $\\beta_j$ se interpreta como el efecto que tiene sobre $Y$ el aumento de una unidad en $X_j$ , manteniendo fijos todos los demás predictores.\n",
        "\n",
        "En el ejemplo de las ventas y publicidad: \n",
        "\n",
        "$$sales = \\beta_0 + \\beta_1 \\times TV + \\beta_2 \\times radios + \\beta_3 \\times newspaper + \\epsilon $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyYeuH-H36-h"
      },
      "source": [
        "### Estimación de los coeficientes de regresión\n",
        "\n",
        "Al igual que en la regresión lineal simple, los coeficientes de regresión $\\beta_0, \\beta_1, ..., \\beta_p$  son desconocidos, y deben ser estimados. Una vez etimados, podemos hacer predicciones usando la fórmula:\n",
        "\n",
        "$$\\hat y = \\hat \\beta_0 + \\hat \\beta_1x_1 + \\hat \\beta_2x_2 + ... + \\hat \\beta_p x_p$$\n",
        "\n",
        "Los parámetros se estiman usando el mismo enfoque de mínimos cuadrados que vimos en el contextos de la regresión lineal simple. Elegimos $\\beta_0, \\beta_1, ..., \\beta_p$ para minimizar la suma de los residuos cuadráticos:\n",
        "\n",
        "$$RSS = \\sum_{i=1}^{n} (y_i - \\hat y_i)^2 = \\sum_{i=1}^{n} (y_i - \\beta_0 - \\hat \\beta_1x_{i1} - \\hat \\beta_2x_{i2} - ... - \\hat \\beta_p x_{ip})^2$$\n",
        "\n",
        "Sin embargo, a diferencia de la regresión lineal simple,  las estimaciones de los coeficientes de regresión múltiple tienen formas algo complejas que se representan utilizando matrices algebraicas. \n",
        "\n",
        "La figura 6 muestra un ejemplo de los mínimos cuadrados para ajustar un dataset con dos predictores. En un entorno tridimensional, con dos predictores y una respuesta, la línea de regresión de menos cuadrados se convierte en un plano. El plano se elige de forma que minimice la suma de las distancias verticales al cuadrado entre cada observación (en rojo) y el plano.\n",
        "\n",
        "<center>\n",
        "<p>\n",
        "<img src=\"https://i.gyazo.com/59b74133deffecd2fb1be62babcde26c.png\" width=\"60%\"/>\n",
        "<figcaption>Fig.6  </figcaption>\n",
        "</p>\n",
        "</center>\n",
        "\n",
        "La tabla de la figura 7 muestra las estimaciones del coeficiente de regresión múltiple cuando los presupuestos de publicidad en TV,  radio y periódicos se utilizan para predecir las ventas de productos. Estos valores se interpretan de la siguiente manera: para una determinada cantidad de dinero invertida en la publicidad de televisión y periódicos, invertir 1.000 dólares adicionales en la publicidad en radio lleva a un aumento de las ventas de aproximadamente 189 unidades. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<center>\n",
        "<p>\n",
        "<img src=\"https://i.gyazo.com/b3feeba3e718373fbef306f072fe3a4d.png\" width=\"40%\"/>\n",
        "<figcaption>Fig.7 Para los datos de ventas, estimaciones del coeficiente de mínimos cuadrados de la regresión lineal múltiple del número de unidades vendidas en la radio, la televisión y el periódico.  </figcaption>\n",
        "</p>\n",
        "</center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKHKB5133_uH"
      },
      "source": [
        "### Algunas preguntas importantes\n",
        "\n",
        "Cuando utilizamos una regresión lineal múltiple, estamos intersados en respodenr a las siguientes preguntas:\n",
        "\n",
        "1. ¿Hay algún predictor $X_1, X_2, ... , X_p$ útil para predecir la respuesta?\n",
        "\n",
        "1. ¿Ayudan todos los predictores a explicar $Y$, o solo son útiles un subconjunto de los predictores? \n",
        "\n",
        "1. ¿Cómo de bien se ajusta el modelo a los datos?\n",
        "\n",
        "1. Dado un conjunto de valores para las variables predictoras, ¿qué valor de respuesta deberíamos predecir? y, ¿cómo de precisa es nuestra predicción?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7pxCO7SRncx"
      },
      "source": [
        "#### ¿Hay relación entre la respueta y los predictores?\n",
        "\n",
        "Recordemos que en el ajuste de regresión lineal simple, para determinar si hay una relación entre la respuesta y el predictor podemos simplemente comprobar si $\\beta_1 = 0$.  En la regresión múltiple con p predictores, tenemos que preguntar si todos los coeficientes de regresión son cero, es decir, si $\\beta_1 = \\beta_2 = ... = \\beta_p = 0$. Como en la regresión lineal simple\n",
        "utilizamos una prueba de hipótesis para responder a esta pregunta.\n",
        "\n",
        "$$H_0 : \\beta_1 = \\beta_2 = ... = \\beta_p = 0$$\n",
        "$$ H_a : al\\;menos\\;un\\;\\beta_j\\;no\\;es\\;cero$$\n",
        "\n",
        "Esta prueba de hipótesis se realiza utilizando el estadístico F:\n",
        "\n",
        "$$ F = \\frac{(TSS - RSS) / p}{RSS / (n - p - 1)}$$\n",
        "\n",
        "donde, como en el modelo lineal simple, $TSS = \\sum(y_i - \\hat y)^2$ y $RSS = \\sum (y_i - \\hat y_i)^2$. Si las suposiciones sobre el modelo lineal son correctas, se puede desmotrar que:\n",
        "\n",
        "$$E{RSS/(n − p − 1)} = \\sigma^2$$\n",
        "\n",
        "y, de esta forma $H_0$ es verdadera:\n",
        "\n",
        "$$E{(TSS − RSS)/p} = \\sigma^2$$\n",
        "\n",
        "Por lo tanto, cuando no hay relación entre la respuesta y los predictores, $F$ tomara un valor cercano a 1. Por otro lado, si $H_a$ es cierto, entonces $E{(TSS - RSS)/p} > \\sigma2$, así que esperamos que $F$ sea mayor que 1.\n",
        "\n",
        "El estadístico F para el modelo de regresión lineal múltiple en el ejemplo de las ventas  se muestra en la tabla de la figura 8. En este caso, el valor obtenido de F es 570. Como es mucho más grande que 1, proporciona una evidencia convincente contra la hipótesis nula H0. En otras palabras, el estadístico F sugiere que al menos uno de los medios de publicidad debe estar relacionado con las ventas.\n",
        "\n",
        "\n",
        "<center>\n",
        "<p>\n",
        "<img src=\"https://i.gyazo.com/942322f48f1a631938b5388790170af3.png\" width=\"30%\"/>\n",
        "<figcaption>Fig.8  </figcaption>\n",
        "</p>\n",
        "</center>\n",
        "\n",
        "\n",
        "Sin embargo, ¿y si el valor de F hubiera estado más cerca de\n",
        "1? ¿Cómo de  grande tiene que ser la  F para que podamoos rechazar $H_0$ y\n",
        "concluir que existe una relación? Resulta que la respuesta depende\n",
        "de los valores de n y p. Cuando n es grande, una estadística F poco mayor que 1 podría todavía proporcionar la suficiente evidencia contra H0. Por el contrario, cuando n es pequeño,  se necesita un valor de F más grande para rechazar $H_0$.\n",
        "\n",
        "El enfoque de usar F para probar si existe alguna relación entre los predictores y la respuesta funciona cuando $p$ es relativamente pequeño comparado con $n$. Sin embargo, a veces tenemos un número muy grande de variables. Si $p > n$ entonces hay más coeficientes $\\beta_j$ para estimar que las observaciones a partir de las cuales estimarlas. En este caso ni siquiera podemos ajustar el modelo de regresión lineal múltiple usando los mínimos cuadrados, por lo que el estadístico F no se puede utilizar. Cuando $p$ es grande, se pueden utilzar algunos enfoques que veremos más adelante, como la **selección previa** (*forward selection*).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVuVXD2ERvqZ"
      },
      "source": [
        "#### Determinar las variables importantes\n",
        "\n",
        "Es posible que todos los pronosticadores estén asociados a la respuesta, pero lo más frecuente es que la respuesta sólo esté relacionada con un subconjunto de los predictores. La tarea de determinar qué predictores están asociados con la respuesta, a fin de ajustar un modelo simple que incluya sólo esos predictores, se conoce como **selección de variables.** Hay tres enfoques diferentes:\n",
        "\n",
        "* **Selección hacia adelante** (*Forward selection*). Las variables se introducen secuencialmente en el modelo. Partimos de un modelo nulo, un modelo que contiene una intersección pero no tiene ningún predictor. Entonces ajustamos p  regresiones lineales simples y añadimos al modelo nulo la variable que tiene el menor RSS. Después añadimos a ese modelo la variable con el RSS más bajo para el nuevo modelo de dos variables. Se repite el proceso hasta que se cumpla alguna regla de detención\n",
        "\n",
        "* **Selección hacia atrás** (*Backward selection*). Se introducen todas las variables en la ecuación y después se van excluyendo una a una, según el p-valor más grande. \n",
        "\n",
        "* **Selección mixta** (*Mixed selection*). Este método es una combinación de los procedimientos anteriores. Comenzamos sin variables en el modelo, y al igual que en la selección hacia adelante, añadimos la variable que proporciona el mejor ajuste. Continuamos añadiendo las variables una a una. En este caso, si en algún momento el p-valor de una de las variables del modelo supera un determina umbral, quitamos esa variable del modelo. \n",
        "\n",
        "La selección hacia atrás no se puede utilizar si $p > n$, mientras que la selección hacia adelante se puede utilizar siempre. Sin embargo, la selección hacia adelante es un enfoque ambicioso, y podría incluir variables que más tarde sean redundantes. La selección mixta soluciona este problema. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B57QvRDsRv5g"
      },
      "source": [
        "#### Ajuste del modelo\n",
        "\n",
        "Dos de las medidas numéricas más comunes para el ajuste del modelo son la RSE y\n",
        "$R^2$. Estas dos cantidades se calculan e interpretan de la misma manera que para la regresión lineal simple. Recordemos que en la regresión simple, $R^2$ es el cuadrado de la correlación entre la respuesta y la variable. En la regresión lineal múltiple, es igual a $Cor(Y, \\hat Y)^2$, el cuadrado de la correlación entre la respuesta y el modelo lineal ajustado; de hecho una propiedad del modelo lineal ajustado es que maximiza esta correlación entre todos los modelos lineales posibles.\n",
        "\n",
        "Un valor de $R^2$ cercano a 1 indica que el modelo explica una gran parte\n",
        "de la variación de la variable de respuesta. A modo de ejemplo, podemos ver en la tabla de la Figura 8, que el modelo que utiliza los tres medios publicitarios tiene un $R^2 = 0.8972$. Por otro lado, el modelo que\n",
        "utiliza sólo la televisión y la radio para predecir las ventas tiene un valor $R^2 = 0.89719$. En otras palabras, hay un pequeño aumento en R2 si incluimos la publicidad en los periódicos en el modelo que ya contiene publicidad en televisión y radio.\n",
        "\n",
        "Parece que $R^2$ siempre aumenta cuando se añaden más variables al modelo, aunque dichas variables solo están débilmente asociadas con la respuesta. Esto se debe a que al añadir otra variable a las ecuaciones de mínimos cuadrados nos permiten ajustar los datos de entrenamiento (aunque no necesariamente los datos de las pruebas) con mayor precisión.\n",
        "\n",
        "Además de analizar las estadísticas de $RSE$ y $R^2$ que acabamos de discutir.\n",
        "puede ser útil trazar gráficamente los datos. Los resúmenes gráficos pueden revelar problemas con un modelo que no es visible en las estadísticas numéricas. Por ejemplo, la figura 9 muestra una trama tridimensional de la televisión y la radio frente a las ventas.\n",
        "\n",
        "<center>\n",
        "<p>\n",
        "<img src=\"https://i.gyazo.com/e42f57125f36c922d161688dd7e905b8.png\" width=\"40%\"/>\n",
        "<figcaption>Fig.7 Para los datos de ventas, estimaciones del coeficiente de mínimos cuadrados de la regresión lineal múltiple del número de unidades vendidas en la radio, la televisión y el periódico.  </figcaption>\n",
        "</p>\n",
        "</center>\n",
        "\n",
        "Podemos ver que algunas observaciones están encima y otras debajo\n",
        "del plano de regresión de mínimos cuadrados. En concreto, el modelo lineal parece sobrestimar las ventas en los casos en que la mayor parte del dinero de la publicidad se gastó exclusivamente en la televisión o la radio. Subestima las ventas en los casos en los que el presupuesto se dividió entre los dos medios.\n",
        "\n",
        "Este pronunciado patrón no lineal no puede ser modelado con precisión usando la regresión lineal. Propone un efecto de sinergia o interacción entre los medios publicitarios, por lo que la combinación de los medios juntos resulta en un mayor impulso para ventas que cuando se utiliza un único medio publicitario.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKx0L7A3RwGZ"
      },
      "source": [
        "#### Predicciones\n",
        "\n",
        "Una vez que hemos ajustado el modelo de regresión lineal múltiple, es posible aplicarlo para predecir la respuesta $Y$ en base a un conjunto de valores para los predictores $X_1, X_2, ..., X_n$. Sin embargo, existen tres tipos de incertidumbre asociada a esta predicción:\n",
        "\n",
        "1. Los coeficientes $\\hat \\beta_0, \\hat \\beta_1, ..., \\hat \\beta_p$ son estimaciones para $\\beta_0, \\beta_1, ..., \\beta_p$. Es decir, el plano de mínimos cuadrados:\n",
        "$$\\hat Y = \\hat \\beta_0 + \\hat \\beta_1 X_1 + ... + \\hat \\beta_p X_p$$\n",
        "\n",
        "es solo una estimación para el verdadero plano de regresión poblacional.  \n",
        "$$ f(X) = \\beta_0 +  \\beta_1 X_1 + ... + \\beta_p X_p$$\n",
        "\n",
        "Podemos calcular un intervalo de confianza para para determinar cómo de cerca estará $\\hat Y$ de $f(X)$.\n",
        "\n",
        "2. Por supuesto, en la práctica, asumir un modelo lineal para f(X) es casi siempre una aproximación a la realidad, por lo que hay una fuente adicional de error potencialmente reducible que llamamos **sesgo del modelo**. Es decir, cuando usamos un modelo lineal, en realidad estamos estimando la mejor aproximación lineal\n",
        "\n",
        "3. Aunque conocieramos $f(X)$, es decir, incluso los verdaderos valores\n",
        "para $\\beta_0, \\beta_1, ... \\beta_p$, el valor de la respuesta no se puede predecir exactamente debido al error $\\epsilon$ del modelo. ¿Cuánto variará $Y$ de $\\hat Y$? Podemos utilizar intervalos de predicción para responder a esta pregunta. Estos intervalos son siempre más amplios que los intervalos de confianza, porque incorporan tanto el error en la estimación de $f(X)$ (el error reducible) y la incertidumbre sobre cuánto un punto particular\n",
        "difiere del plano de regresión de la población (el error irreducible)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgwwXW6u4Kfq"
      },
      "source": [
        "\n",
        "## Otras consideraciones sobre el modelo de regresión\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZUIPcc34Ozj"
      },
      "source": [
        "#### Predictores cualitativos\n",
        "\n",
        "En nuestra discusión hasta ahora, hemos asumido que todas las variables del modelo de regresión son cuantitativas. Pero en la práctica, es habitual que algunos predictores sean cualitativos.\n",
        "\n",
        "Por ejemplo, el conjunto de datos *Credit* que se muestra en la figura 9 registra el saldo (deuda media de las tarjetas de crédito de varias personas), así como varios predictores cuantitativos: edad, tarjetas (número de tarjetas de crédito), educación (años de educación), ingresos (en miles de dólares), límite (límite de crédito), y una calificación (calificación de crédito).\n",
        "\n",
        "Cada subgráfico de la figura 9 es un diagrama de dispersión para un\n",
        "par de variables cuyas características vienen dadas por la fila  y\n",
        "las etiquetas de las columnas. Por ejemplo, el diagrama de dispersión a la derecha de la palabra \"Equilibrio\" representa el equilibrio frente a la edad, mientras que el gráfico a la derecha de \"Edad\" corresponde a la edad frente a la tarjeta de crédito. Además de estos datos cuantitativos variables, también tenemos cuatro variables cualitativas: género, estudios, estado civil y etnia (caucásica, afroamericana o asiático).\n",
        "\n",
        "<center>\n",
        "<p>\n",
        "<img src=\"https://i.gyazo.com/70b2f2faafda3b667c61a225496c22a3.png\" width=\"80%\"/>\n",
        "<figcaption>Fig.9. Dataset *Credit*  </figcaption>\n",
        "</p>\n",
        "</center>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsWzOg5J4O4c"
      },
      "source": [
        "#### Predictores solo con dos niveles\n",
        "\n",
        "Supongamos que deseamos investigar las diferencias en el saldo de las tarjetas de crédito entre hombres y mujeres, ignorando por el momento las otras variables. Si un predictor cualitativo (también conocido como factor) solo tiene dos niveles o valores posibles, entonces incorporarlo a un modelo de regresión es muy simple. Simplemente creamos un indicador o variable ficticia que toma dos posibles valores numéricos. Por ejemplo, basándonos en la variable de **género**, podemos crear una nueva variable que tome la forma\n",
        "\n",
        "$$ x_i = \\left\\{ \\begin{array}{lcc}\n",
        "             1 &   si  & \\text{i-ésima persona es mujer} \\\\\n",
        "             \\\\ 0 &  si & \\text{i-ésima persona es hombre}  \\\\\n",
        "             \\end{array}\n",
        "   \\right.\n",
        "$$\n",
        "\n",
        "y utilizar esta variable como un predictor en la ecuación de regresión. Eso da como resultado el modelo\n",
        "\n",
        "$$ y_i = \\beta_0 + \\beta_1 x_1 + \\epsilon_i = \\left\\{ \\begin{array}{lcc}\n",
        "             \\beta_0 + \\beta_1 + \\epsilon_i &   si  & \\text{i-ésima persona es mujer} \\\\\n",
        "             \\\\ \\beta_0 + \\epsilon_i &  si & \\text{i-ésima persona es hombre}  \\\\\n",
        "             \\end{array}\n",
        "   \\right.\n",
        "$$\n",
        "\n",
        "Ahora, $\\beta_0$ se puede interpretar como el saldo promedio de la tarjeta de crédito entre hombres, $\\beta_0$ + $\\beta_1$ como el saldo promedio de la tarjeta de crédito entre las mujeres y $\\beta_1$ como la diferencia promedio en el saldo de la tarjeta de crédito entre mujeres y hombres.\n",
        "\n",
        "<center>\n",
        "<p>\n",
        "<img src=\"https://i.gyazo.com/22887bd05a09853178dd6dc6f2509a67.png\" width=\"80%\"/>\n",
        "<figcaption>Fig.10.  </figcaption>\n",
        "</p>\n",
        "</center>\n",
        "\n",
        "La Figura 10 muestra las estimaciones de coeficientes y otra información asociada con el modelo. Se estima que la deuda de tarjeta de crédito promedio para los hombres es de $\\$$ 509,80, mientras que se estima que las mujeres tienen una deuda adicional de $\\$$ 19,73 por un total de $\\$$ 509,80 + $\\$$ 19,73 = $\\$$ 529,53. Sin embargo, notamos que el valor p de la variable ficticia es muy alto. Esto indica que no hay evidencia estadística de una diferencia en el saldo promedio de las tarjetas de crédito entre los géneros.\n",
        "\n",
        "La decisión de codificar mujeres como 1 y hombres como 0 en es arbitraria y no tiene ningún efecto sobre el ajuste de regresión, pero altera la interpretación de los coeficientes. Alternativamente, en lugar de un esquema de codificación 0/1, podríamos crear una variable ficticia\n",
        "\n",
        "$$ x_i = \\left\\{ \\begin{array}{lcc}\n",
        "             1 &   si  & \\text{i-ésima persona es mujer} \\\\\n",
        "             \\\\ -1 &  si & \\text{i-ésima persona es hombre}  \\\\\n",
        "             \\end{array}\n",
        "   \\right.\n",
        "$$\n",
        "\n",
        "y use esta variable en la ecuación de regresión. Esto da como resultado el modelo\n",
        "\n",
        "$$ y_i = \\beta_0 + \\beta_1 x_1 + \\epsilon_i = \\left\\{ \\begin{array}{lcc}\n",
        "             \\beta_0 + \\beta_1 + \\epsilon_i &   si  & \\text{i-ésima persona es mujer} \\\\\n",
        "             \\\\ \\beta_0  - \\beta_1 + \\epsilon_i &  si & \\text{i-ésima persona es hombre}  \\\\\n",
        "             \\end{array}\n",
        "   \\right.\n",
        "$$\n",
        "\n",
        "Ahora $\\beta_0$ se puede interpretar como el saldo promedio total de la tarjeta de crédito (ignorando el efecto de género), y $\\beta_1$ es la cantidad que las mujeres están por encima del promedio y los hombres por debajo del promedio. En este ejemplo, la estimación de $\\beta_0$ sería $\\$$ 519.665, a medio camino entre los promedios masculinos y femeninos de $\\$$ 509.80 y $\\$$ 529.53. La estimación de $\\beta_1$ sería de $\\$$ 9.865, que es la mitad de $\\$$ 19.73, la diferencia promedio entre mujeres y hombres. Es importante señalar que las predicciones finales para los saldos acreedores de hombres y mujeres serán idénticas independientemente del esquema de codificación utilizado. La única diferencia está en la forma en que se interpretan los coeficientes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QS7itaDa4O75"
      },
      "source": [
        "#### Predictores cualitativos con más de dos niveles\n",
        "\n",
        "Cuando un predictor cualitativo tiene más de dos niveles, una sola variable ficticia no puede representar todos los valores posibles. En esta situación, podemos crear variables ficticias adicionales. Por ejemplo, para la variable de etnia creamos dos variables ficticias. El primero podría ser\n",
        "\n",
        "$$ x_{i1} = \\left\\{ \\begin{array}{lcc}\n",
        "             1 &   si  & \\text{i-ésima persona es asiática} \\\\\n",
        "             \\\\ 0 &  si & \\text{i-ésima persona no es asiática}  \\\\\n",
        "             \\end{array}\n",
        "   \\right.\n",
        "$$\n",
        "\n",
        "Y la segunda podría ser\n",
        "\n",
        "$$ x_{i2} = \\left\\{ \\begin{array}{lcc}\n",
        "             1 &   si  & \\text{i-ésima persona es caucásico} \\\\\n",
        "             \\\\ 0 &  si & \\text{i-ésima persona no es caucásico}  \\\\\n",
        "             \\end{array}\n",
        "   \\right.\n",
        "$$\n",
        "\n",
        "Entonces, ambas variables pueden usarse en la ecuación de regresión, para obtener el modelo\n",
        "\n",
        "$$ y_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\epsilon_i = \\left\\{ \\begin{array}{lcc}\n",
        "             \\beta_0 + \\beta_1 + \\epsilon_i &   si  & \\text{i-ésima persona es asiática} \\\\\n",
        "             \\\\ \\beta_0  + \\beta_2 + \\epsilon_i &  si & \\text{i-ésima persona es caucásica}  \\\\\n",
        "             \\\\ \\beta_0  +  \\epsilon_i &  si & \\text{i-ésima persona es afroamericana}  \\\\\n",
        "             \\end{array}\n",
        "   \\right.\n",
        "$$\n",
        "\n",
        "Ahora $\\beta_0$ se puede interpretar como el saldo promedio de la tarjeta de crédito para afroamericanos, $\\beta_1$ se puede interpretar como la diferencia en el saldo promedio entre las categorías asiática y afroamericana, y $\\beta_2$ se puede interpretar como la diferencia en el saldo promedio entre las categorías caucásicas y afroamericanas. Siempre habrá una variable ficticia menos que el número de niveles. El nivel sin variable ficticia (afroamericano en este ejemplo) se conoce como línea de base.\n",
        "\n",
        "<center>\n",
        "<p>\n",
        "<img src=\"https://i.gyazo.com/d3e9e9150ef706c1bd7a10c600b7cbd7.png\" width=\"80%\"/>\n",
        "<figcaption>Fig.11.  </figcaption>\n",
        "</p>\n",
        "</center>\n",
        "\n",
        "En la Figura 11, vemos que el saldo estimado para la línea de base(*baseline*), afroamericano, es $\\$$ 531.00. Se estima que la categoría asiática tendrá $\\$$ 18,69 menos de deuda que la categoría afroamericana, y que la categoría caucásica tendrá $\\$$ 12,50 menos deuda que la categoría afroamericana. Sin embargo, los p-valores asociados con las estimaciones de los coeficientes para las dos variables ficticias son muy grandes, lo que sugiere que no hay evidencia estadística de una diferencia real en el saldo de las tarjetas de crédito entre las etnias. Una vez más, el nivel seleccionado como categoría de referencia es arbitrario y las predicciones finales para cada grupo serán las mismas independientemente de esta elección. Sin embargo, los coeficientes y sus p-valores dependen de la elección de la codificación de la variable ficticia. En lugar de confiar en los coeficientes individuales, podemos usar una prueba $F$ para probar $H_0: \\beta_1 = \\beta_2 = 0$; esto no depende de la codificación Esta prueba $F$ tiene un p-valor de 0.96, lo que indica que no podemos rechazar la hipótesis nula de que no existe relación entre el equilibrio y la etnia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVURzszC4O-4"
      },
      "source": [
        "### Extensiones del modelo lineal\n",
        "\n",
        "El modelo de regresión lineal estándar proporciona resultados interpretables y funciona bastante bien en muchos problemas del mundo real. Sin embargo, hace varios supuestos muy restrictivos que a menudo se violan en la práctica. Dos de los supuestos más importantes establecen que la relación entre los predictores y la respuesta es aditiva y lineal. El supuesto aditivo significa que el efecto de los cambios en un predictor $X_j$ sobre la respuesta $Y$ es independiente de los valores de los otros predictores. El supuesto lineal establece que el cambio en la respuesta $Y$ debido a un cambio de una unidad en $X_j$ es constante, independientemente del valor de $X_j$. En este libro, examinamos varios métodos sofisticados que relajan estos dos supuestos. Aquí, examinamos brevemente algunos enfoques clásicos comunes para extender el modelo lineal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9ZEyEOX4PBi"
      },
      "source": [
        "#### Eliminación de la suposición aditiva\n",
        "\n",
        "En nuestro análisis anterior de los datos de **advertising**, llegamos a la conclusión de que tanto la **tv** como la **radio** parecen estar asociadas con las **ventas**. Los modelos lineales que formaron la base para esta conclusión asumieron que el efecto sobre las ventas de aumentar un medio publicitario es independiente de la cantidad gastada en los otros medios.\n",
        "\n",
        "Sin embargo, este modelo simple puede ser incorrecto. Suponga que gastar dinero en publicidad en radio en realidad aumenta la efectividad de la publicidad televisiva, de modo que el término pendiente para la televisión debería aumentar a medida que aumenta la radio. En esta situación, dado un presupuesto fijo de $ 100.000, gastar la mitad en radio y la otra mitad en televisión puede incrementar las ventas más que asignar la cantidad total a televisión o radio. En marketing, esto se conoce como efecto de sinergia, y en estadística, como efecto de acción inter. La figura 7 sugiere que tal efecto puede estar presente en los datos publicitarios. Tenga en cuenta que cuando los niveles de televisión o radio son bajos, las ventas reales son más bajas que las predichas por el modelo lineal.\n",
        "\n",
        "Considere el modelo de regresión lineal estándar con dos variables,\n",
        "$$Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\epsilon  $$\n",
        "\n",
        "Según este modelo, si aumentamos $X_1$ en una unidad, entonces $Y$ aumentará en un promedio de $\\beta_1$ unidades. Observe que la presencia de $X_2$ no altera esta afirmación; es decir, independientemente del valor de $X_2$, un aumento de una unidad en $X_1$ conducirá a un aumento de unidades $\\beta_1$ en $Y$. Una forma de extender este modelo para permitir efectos de interacción es incluir un tercer predictor, llamado término de interacción, que se construye calculando el producto de $X_1$ y $X_2$. Esto da como resultado el modelo:\n",
        "\n",
        "$$Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 X_1 X_2 + \\epsilon $$\n",
        "\n",
        "¿Cómo la inclusión de este término de interacción relaja el supuesto aditivo? Tenga en cuenta que se puede reescribir como\n",
        "\n",
        "$$ Y = \\beta_0 + (\\beta_1 + \\beta_3 X_2)X_1 + \\beta_2 X_2 + \\epsilon = \\beta_0 + \\widetilde{\\beta}_1 X_1+ \\beta_2 X_2 + \\epsilon $$\n",
        "\n",
        "donde $ \\widetilde{\\beta}_1 = \\beta_1 + \\beta_3 X_2 $. Dado que $\\widetilde{\\beta}_1$ cambia con $X_2$, el efecto de $X_1$ en $Y$ ya no es constante: ajustar $X_2$ cambiará el impacto de $X_1$ en $Y$.\n",
        "\n",
        "Un modelo lineal que usa **radio**, **televisión** y una interacción entre los dos para predecir las **ventas** toma la forma:\n",
        "\n",
        "$$ \\text{sales} = \\beta_0 + \\beta_1 · \\text{TV} + \\beta_2 · \\text{radio} + \\beta_3 · (\\text{radio} · \\text{TV}) + \\epsilon = \\beta_0 + (\\beta_1 + \\beta_3 · \\text{radio}) · \\text{TV} + \\beta_2 · \\text{radio} + \\epsilon $$\n",
        "\n",
        "Podemos interpretar $\\beta_3$ como el aumento en la efectividad de la publicidad televisiva para un aumento de una unidad en la publicidad de radio (o viceversa). Los coeficientes que resultan del ajuste del modelo se dan en la Figura 12.\n",
        "\n",
        "<center>\n",
        "<p>\n",
        "<img src=\"https://i.gyazo.com/8f280a3260f4955816651b970535c72b.png\" width=\"80%\"/>\n",
        "<figcaption>Fig.12.  </figcaption>\n",
        "</p>\n",
        "</center>\n",
        "\n",
        "Los resultados de la Figura 12 sugieren fuertemente que el modelo que incluye el término de interacción es superior al modelo que solo contiene efectos principales. El p-valor para el término de interacción, TV × radio, es extremadamente bajo, lo que indica que existe una fuerte evidencia de $H_a: \\beta_3 = 0$. En otras palabras, está claro que la verdadera relación no es aditiva. El $R^2$ para el modelo (modelo superior de sales = ...) es 96.8%, comparado con sólo 89.7% para el modelo que predice las ventas usando TV y radio sin un término de interacción. Esto significa que $(96,8-89,7) / (100-89,7) = 69\\%$ de la variabilidad en las ventas que queda después de ajustar el modelo aditivo ha sido explicada por el término de interacción. Las estimaciones del coeficiente en la Figura 12 sugieren que un aumento en la publicidad televisiva de $\\$$ 1,000 está asociado con un aumento en las ventas de $(\\hat{\\beta}_1 + \\hat{\\beta}_3 × \\text{radio}) × 1,000 = 19 + 1.1 × \\text{unidades de radio}$. Y un aumento en la publicidad radial de $\\$$ 1,000 se asociará con un aumento en las ventas de $(\\hat{\\beta}_2 + \\hat{\\beta}_3 × TV) × 1,000 = 29 + 1.1 × \\text{unidades de TV}$\n",
        "\n",
        "En este ejemplo, los p-valores asociados con la televisión, la radio y el término de interacción son todos estadísticamente significativos (Figura 12), por lo que es obvio que las tres variables deben incluirse en el modelo. Sin embargo, a veces ocurre que un término de interacción tiene un valor p muy pequeño, pero los efectos principales asociados (en este caso, la televisión y la radio) no. El principio jerárquico establece que si incluimos una interacción en un modelo, *también debemos incluir los efectos principales, incluso si los p-valores asociados con sus coeficientes no son significativos*.\n",
        "\n",
        "En el ejemplo anterior, consideramos una interacción entre la televisión y la radio, las cuales son variables cuantitativas. Sin embargo, el concepto de interacciones se aplica igualmente a las variables cualitativas o a una combinación de variables cuantitativas y cualitativas. De hecho, una interacción entre una variable cualitativa y una variable cuantitativa tiene una interpretación particularmente agradable. Considere el conjunto de datos crediticios vistos en la figura 9 y suponga que deseamos predecir el equilibrio utilizando las variables de ingresos (cuantitativas) y de estudiantes (cualitativas). En ausencia de un término de interacción, el modelo toma la forma:\n",
        "\n",
        "$$ \\text{balance}_{i} \\approx \\beta_0 + \\beta_1 · \\text{income}_i + \\left\\{ \\begin{array}{lcc}\n",
        "             \\beta_2 &   si  & \\text{i-ésima persona es estudiante} \\\\\n",
        "             \\\\ 0 &  si & \\text{i-ésima persona no es estudiante}  \\\\\n",
        "             \\end{array}\n",
        "   \\right.\n",
        "$$\n",
        "\n",
        "\n",
        "$$ \\text{balance}_{i} = \\beta_1 · \\text{income}_i + \\left\\{ \\begin{array}{lcc}\n",
        "             \\\\ \\beta_0 + \\beta_2 &   si  & \\text{i-ésima persona es estudiante} \\\\\n",
        "             \\\\ \\beta_0 &  si & \\text{i-ésima persona no es estudiante}  \\\\\n",
        "             \\end{array}\n",
        "   \\right.\n",
        "$$\n",
        "\n",
        "Tenga en cuenta que esto equivale a ajustar dos líneas paralelas a los datos, una para estudiantes y otra para no estudiantes. Las líneas para estudiantes y no estudiantes tienen intersecciones diferentes, $\\beta_0 + \\beta_2$ versus $\\beta_0$, pero la misma pendiente, $\\beta_1$. Esto se ilustra en el panel de la izquierda de la Figura 13. El hecho de que las líneas sean paralelas significa que el efecto promedio sobre el equilibrio de un aumento de una unidad en los ingresos no depende de si el individuo es o no estudiante, lo que representa una limitación potencialmente seria del modelo, ya que de hecho un cambio en los ingresos pueden tener un efecto muy diferente en el saldo de la tarjeta de crédito de un estudiante frente a un no estudiante.\n",
        "\n",
        "<center>\n",
        "<p>\n",
        "<img src=\"https://i.gyazo.com/908432ddfde2a4922e502f426052f54c.png\" width=\"80%\"/>\n",
        "<figcaption>Fig.13.  </figcaption>\n",
        "</p>\n",
        "</center>\n",
        "\n",
        "Esta limitación se puede abordar agregando una variable de interacción, creada al multiplicar el ingreso con la variable ficticia para el estudiante. Nuestro modelo ahora se convierte en:\n",
        "\n",
        "$$ \\text{balance}_{i} \\approx \\beta_0 + \\beta_1 · \\text{income}_i + \\left\\{ \\begin{array}{lcc}\n",
        "             \\beta_2 + \\beta_3 · \\text{income}_i &   si  & \\text{ estudiante} \\\\\n",
        "             \\\\ 0 &  si & \\text{no estudiante}  \\\\\n",
        "             \\end{array}\n",
        "   \\right.\n",
        "$$\n",
        "\n",
        "\n",
        "$$ = \\left\\{ \\begin{array}{lcc}\n",
        "             (\\beta_0 + \\beta_2)  + (\\beta_1 + \\beta_3) · \\text{income}_i &   si  & \\text{ estudiante} \\\\\n",
        "             \\\\ \\beta_0 + \\beta_1 · \\text{income}_i &  si & \\text{no estudiante}  \\\\\n",
        "             \\end{array}\n",
        "   \\right.\n",
        "$$\n",
        "\n",
        "Una vez más, tenemos dos líneas de regresión diferentes para los estudiantes y los no estudiantes. Pero ahora esas líneas de regresión tienen diferentes intersecciones, β0 + β2 versus β0, así como diferentes pendientes, $\\beta_1 + \\beta_3$ versus $\\beta_1$. Esto permite la posibilidad de que cambios en los ingresos puedan afectar los saldos de las tarjetas de crédito de estudiantes y no estudiantes de manera diferente. El panel de la derecha de la Figura 13 muestra las relaciones estimadas entre los ingresos y el saldo para estudiantes y no estudiantes en el modelo. Observamos que la pendiente para los estudiantes es menor que la pendiente para los no estudiantes. Esto sugiere que los aumentos en los ingresos están asociados con aumentos más pequeños en el saldo de la tarjeta de crédito entre los estudiantes en comparación con los no estudiantes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q44sabnh4PEe"
      },
      "source": [
        "\n",
        "#### Relaciones no lineales\n",
        "\n",
        "Como hemos visto, el modelo de regresión lineal supone que existe una relación lineal entre los predictores y la respuesta. Sin embargo, en algunos casos, puede que dicha relación no sea lineal.  En estos casos, el modelo de regresión lineal se puede extender para adaptarse a relaciones no lineales, utilizando la **regresión polinomial**. \n",
        "\n",
        "Fijémonos en la Figura 14, en la que se representa el *mpg* (*gas mileage in miles per gallon*) y la potencia en caballos para un número de vehículos del dataset *Auto*. La línea naranja muestra el ajuste de regresión. Podemos observar que existe una relación *curvada* entre ambas variables. \n",
        "\n",
        "\n",
        "<center>\n",
        "<p>\n",
        "<img src=\"https://i.gyazo.com/83aa74e906023a23033e36b14690df60.png\" width=\"60%\"/>\n",
        "<figcaption>Fig.14.  Dataset Auto. Para un número de vehículos, representa el gas emitido y la potencia en caballos. </figcaption>\n",
        "</p>\n",
        "</center>\n",
        "\n",
        "Para asociaciones no lineales en un modelo lineal, podemos calcular una versión transformada de los predictores. Por ejemplo, los puntos de la gráfica anterior parecen tener una forma cuadrática, sugiriendo que el modelo es de la forma:\n",
        "\n",
        "$$mpg = \\beta_0 + \\beta_1 \\times \\text{horsepower} + \\beta_2 \\times \\text{horsepower}^2 + \\varepsilon $$\n",
        "\n",
        "Con la función anterior, podemos estimar *mpg* utilizando una función no lineal de *horsepower*, pero sigue siendo un modelo lineal.  Es decir, es un modelo sencillo de regresión lineal múltiple con $X_1 = \\text{horsepower}$ y $X_2 = \\text{horsepower}^2$, por lo que podemos utilizamos el mismo software de regresión lineal para estimar los parámetros $\\beta_0$, $\\beta_1$ y $\\beta_2$.\n",
        "\n",
        "La curva azul en la Figura 14 muesrta el resultado de este ajuste cuadrático. El $R^2$ del ajuste cuadrático es 0.688, que comparado con el 0.606 para el ajuste lineal, y el p-valor para el término cuadrático es significativamente más alto (tabla de la Figura 15).\n",
        "\n",
        "<center>\n",
        "<p>\n",
        "<img src=\"https://i.gyazo.com/e25fa2cf86e250b33d106704c5eaf9c6.png\" width=\"50%\"/>\n",
        "<figcaption>Fig.15.  Para el dataset Auto, coeficiente de mínimos cuadrados asociado con la regresión de $mpg$ en función de $hoserpower$ y $hoserpower^2$ </figcaption>\n",
        "</p>\n",
        "</center>\n",
        "\n",
        "La curva verde en la Figura 14 muestra el ajuste resultante de incluir hasta polinomios de quinto grado en el modelo. El resultado parece ser innecesariamente ondulado, y parece que incluir polinomios de un grado mayor no conduce a mejores resultados.\n",
        "\n",
        "Este enfoque que hemos descrito se conoce como **regresión polinomial**, ya que hemos incluido funciones polinómicas para los predictores del modelo de regresión."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nc682GVO5AbX"
      },
      "source": [
        "### Problemas potenciales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j87tkoLDedDu"
      },
      "source": [
        "Cuando ajustamos un modelo de regresión a un dataset concreto, pueden ocurrir varios problemas. Los más comunes son:\n",
        "\n",
        "\n",
        "\n",
        "*   Relación no lineal entre los predictores y la respuesta\n",
        "*   Correlación de los términos de error\n",
        "*   Varianza no constante de los términos de error.\n",
        "*   Valores atípicos (outliers)\n",
        "*  Puntos con un valor alto (*High-leverage points*)\n",
        "*  Colinealidad.\n",
        "\n",
        "Vamos a ver un pequeño resumen sobre estos puntos\n",
        "\n",
        "\n",
        "####  Relación no lineal entre los predictores y la respuesta\n",
        "\n",
        "El modelo de regresión lineal asume que existe una estricta relación lineal entre los predictores y la respuesta. Sin embargo, si la auténtica relación está lejos de ser lineal, entonces prácticamente todas las conclusiones que sacamos serán muy son discutibles. Además, la precisión de la predicción del modelo será considerablemente menor.\n",
        "\n",
        "Las gráficas de residuos ***residual plots*** son una herramienta muy útil para encontrar falta de linealidad. Dado un modelo de regresión lineal simple, podemos graficar los residuos, $e_i = y_i - \\hat{y}_i$ frente al predictor $x_i$. Para los modelos de regresión múltiple, puesto que hay varios predictores, podemos representar el vector de residuos frente a los valores predichos de $\\hat{y}_i$. \n",
        "\n",
        "La parte izquierda de la Figura 16 es un gráfico de residuos para el modelo de regresión lineal de $mpg$ frente a $horsepower$ en el dataset de *Auto*. La línea roja es un ajuste suave a los residuos, que se muestra para facilitar la identificación de cualquier patrón. Los residuos muestran una clara forma de U, una clara indicación de que la relación es no lineal. Por otro lado, la parte derecha de la Figura 16 muestra el gráfico de residuos del modelo que contenía términos cuadráticos. En este caso, parece que el patrón de forma de U es menor, lo que significa que introducir términos cuadráticos mejora el ajuste del modelo.  \n",
        "\n",
        "<center>\n",
        "<p>\n",
        "<img src=\"https://i.gyazo.com/2947c3d7fa41a60423acaf9b3d5793d2.png\" width=\"70%\"/>\n",
        "<figcaption>Fig.16.  Gráfico de residuos frente a los valores predichos para el dataset Auto. </figcaption>\n",
        "</p>\n",
        "</center>\n",
        "\n",
        "####  Correlación de los términos de error\n",
        "\n",
        "<center>\n",
        "<p>\n",
        "<img src=\"https://i.gyazo.com/7cd19090372ebce4bd5059c7cbb5b003.png\" width=\"70%\"/>\n",
        "<figcaption>Fig.17</figcaption>\n",
        "</p>\n",
        "</center>\n",
        "\n",
        "####  Varianza no constante de los términos de error\n",
        "\n",
        "Otra suposición importante del modelo de regresión lineal es que los términos de error tienen una varianza constante, $Var(\\varepsilon_i) = \\sigma^2$. Los errores estándar, intervalos de confianza, y pruebas de hipótesis asociadas al modelo lineal se basan en esta suposición.\n",
        "\n",
        "Sin embargo, a veces se da el caso de que las varianzas de los términos de error no son constantes, y por ejemplo, incrementan con el valor de la respuesta. Se dice que un modelo de regresión lineal presenta **heterocedasticidad** cuando la varianza de los errores no es constante en todas las observaciones realizadas. Podemos identificar estas varianzas no constantes por la presencia de una forma de embudo en el gráfico de residuos.\n",
        "\n",
        "Como ejemplo se muestra el gráfico izquierdo de la Figura 18, en el que la magnitud de los residuos tiende a aumentar con los valores ajustados. Una posible solución a este problema consite en tranformar la repuesta $Y$ utilizando una función cóncava como $\\log Y$ o $\\sqrt{Y}$. Esa transformación da lugar a una reducción de las respuestas de mayor magnitud, lo que conduce a una reducción de la heteroscedasticidad.\n",
        "\n",
        "En la parte derecha de la Figura 18, se muestra un gráfico de residuos después de transformar la respuesta utilizando $\\log Y$. Los residuos ahora parecen tener una varianza constante, aunque hay algunos indícios de una ligera relación no lineal en los datos.\n",
        "\n",
        "<center>\n",
        "<p>\n",
        "<img src=\"https://i.gyazo.com/5d958a623ee6efe17f29aafac5967ee6.png\" width=\"70%\"/>\n",
        "<figcaption>Fig.18</figcaption>\n",
        "</p>\n",
        "</center>\n",
        "\n",
        "\n",
        "####  Valores atípicos (outliers)\n",
        "\n",
        "Un *outlier*  es una observación que es numéricamente distante del resto de los datos. Los valores atípicos pueden surgir por diversas razones, como el registro incorrecto de una observación durante la recopilación de datos.\n",
        "\n",
        "El punto rojo (observación 20) en el panel izquierdo de la Figura 19 es un ejemplo de valor atípico. La línea roja es el ajuste de mínimos cuadrados, mientras que la línea de puntos azul es el ajuste de mínimos cuadrados cuando se elimina el *outlier*. En este caso, quitar el *outlier* tiene un pequeño efecto sobre la línea de mínimos cuadrados: no provoca casi ningún cambio en la pendiente, y solo una pequeña reducción en la interseción.\n",
        "\n",
        "En este ejemplo, el RSE es 0.19 cuando el outlier se incluye en la regresión, y es de 0.77 cuando se quita el valor atípico. Dado que RSE se utiliza para calcular todos los intervalos de confianza y p-valores, un aumento tan significativo provocado por un solo punto de datos puede tener\n",
        "implicaciones importantes en la interpretación del ajuste. De igual forma, incluir el outlier hace que $R^2$ se reduzca de 0.892 a 0.805.\n",
        "\n",
        "Los gráficos de residuos pueden ser útiles para identificar valores atípicos. En este ejemplo, el outlier se observa claramente en el gráfico de residuos mostrado en el panel central de la Figura 19. Sin embargo, en la práctica, es difícil decidir cuándo determinar que un punto es un valora atípico. Para abordar este problema, en vez de utilizar el gráfico de resiudos podemos representar los **residuos estudentizados** (*studentized residuals*), calculado como la división de cada residuo $e_i$, por su error estándar estimado. Las observaciones cuyos residuos estudentizados son mayores que 3 en valor absoluto, son potenciales valores atípicos. En el panel derecho de la Figura 19, el valor atípico tiene un residuo estudentizado de 6, mientras que el resto de las observaciones oscilan entre -2 y 2. \n",
        "\n",
        "Si pensamos que el valor atípico se debe a un error en la recogida de los datos, podemos simplemente eliminar esa observación. \n",
        "\n",
        "<center>\n",
        "<p>\n",
        "<img src=\"https://i.gyazo.com/d5d3bd3951a86b7726f44b11e752c739.png\" width=\"80%\"/>\n",
        "<figcaption>Fig.19</figcaption>\n",
        "</p>\n",
        "</center>\n",
        "\n",
        "####  Puntos con un valor alto (*High-leverage points*)\n",
        "####  Colinealidad.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_RrexXv5MvW"
      },
      "source": [
        "## Lab: Linear Regression "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mr3-LyC5B7F",
        "outputId": "35553792-7525-437d-9d89-911c55af22e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "library (MASS)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-70f80e0e4b46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlibrary\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mMASS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'library' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFNMDENmtif4",
        "outputId": "32435737-a7b2-4ad5-bd5a-9e1505ac25f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "myString <- \"Hello, World!\"\n",
        "print(myString)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-3c344868f4a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmyString\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0;34m\"Hello, World!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyString\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'myString' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DSRmSeGt8sN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}